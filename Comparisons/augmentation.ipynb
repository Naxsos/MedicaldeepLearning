{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-26T09:08:20.356282Z",
     "start_time": "2025-03-26T09:07:34.057863Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import ResNet50, DenseNet121\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "\n",
    "NUMBER_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_vgg16_model(image_size):\n",
    "    base_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3), pooling=None)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Conv2D(2048, (1, 1), activation='relu')) # Transition Layer\n",
    "    model.add(GlobalAveragePooling2D())   \n",
    "    model.add(Dense(NUMBER_CLASSES, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=[AUC(multi_label=True)])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T09:09:30.066926Z",
     "start_time": "2025-03-26T09:09:30.056264Z"
    }
   },
   "id": "79cb999a4d83fd3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def normalize_image(img, label):\n",
    "    img = tf.cast(img, np.float32)# / 255.0\n",
    "    img = tf.keras.applications.resnet.preprocess_input(img)\n",
    "    return img, label\n",
    "\n",
    "def create_train_dataset(images_train, labels_train, batch_size=16):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images_train, labels_train))\n",
    "    train_dataset = train_dataset.map(normalize_image)\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=100)\n",
    "    train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "    train_dataset = train_dataset.repeat()\n",
    "    return train_dataset\n",
    "\n",
    "def create_val_dataset(images_val, labels_val, batch_size=16):\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images_val, labels_val))\n",
    "    val_dataset = val_dataset.map(normalize_image)\n",
    "    val_dataset = val_dataset.batch(batch_size, drop_remainder=False)\n",
    "    return val_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T09:09:30.655561Z",
     "start_time": "2025-03-26T09:09:30.619300Z"
    }
   },
   "id": "148bd6749be4cef2",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_model(model, images_test, labels_test, batch_size=16):\n",
    "\n",
    "    images_test_2 = tf.cast(images_test, np.float32) / 255.0\n",
    "    predictions = model.predict(images_test_2, batch_size=batch_size)\n",
    "    \n",
    "    auc_per_class = []\n",
    "    \n",
    "    for class_idx in range(NUMBER_CLASSES):\n",
    "        true_labels_class = labels_test[:, class_idx]\n",
    "        \n",
    "        auc = sklearn.metrics.roc_auc_score(true_labels_class, predictions[:, class_idx])\n",
    "        auc_per_class.append(auc)\n",
    "        \n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(labels_test, axis=1)\n",
    "    balanced_accuracy = sklearn.metrics.balanced_accuracy_score(true_classes, predicted_classes)\n",
    "    accuracy = sklearn.metrics.accuracy_score(true_classes, predicted_classes)\n",
    "    \n",
    "    return auc_per_class, balanced_accuracy, accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T09:09:31.396799Z",
     "start_time": "2025-03-26T09:09:31.384559Z"
    }
   },
   "id": "26437bb7d6fe546e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUMBER_OF_IMAGES = 20000\n",
    "IMAGE_SIZE = 224\n",
    "evaluations={}\n",
    "\n",
    "with open(f\"augmentation_data/images_clean.pkl\", \"rb\") as file:\n",
    "    images_clean = pickle.load(file)[:100]\n",
    "with open(f\"augmentation_data/labels_clean.pkl\", \"rb\") as file:\n",
    "    labels_clean = pickle.load(file)[:100]\n",
    "with open(f\"augmentation_data/images_test.pkl\", \"rb\") as file:\n",
    "    images_test = pickle.load(file)[:100]\n",
    "with open(f\"augmentation_data/labels_test.pkl\", \"rb\") as file:\n",
    "    labels_test = pickle.load(file)[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T11:04:39.520895Z",
     "start_time": "2025-03-26T11:04:35.330408Z"
    }
   },
   "id": "10e30d2db6653e7e",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(f\"augmentation_data/images_horizontal_flip.pkl\", \"rb\") as file:\n",
    "    images_horizontal_flip = pickle.load(file)\n",
    "with open(f\"augmentation_data/images_horizontal_flip.pkl\", \"rb\") as file:\n",
    "    images_vertical_flip = pickle.load(file)\n",
    "with open(f\"augmentation_data/images_rotation.pkl\", \"rb\") as file:\n",
    "    images_rotation = pickle.load(file)\n",
    "with open(f\"augmentation_data/images_crop.pkl\", \"rb\") as file:\n",
    "    images_crop = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "837f90f1299b6481"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 652ms/step - auc: 0.3901 - loss: 1.4385 - val_auc: 0.5087 - val_loss: 1.4302 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 284ms/step - auc: 0.5557 - loss: 1.2329 - val_auc: 0.6582 - val_loss: 1.1895 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 270ms/step - auc: 0.7113 - loss: 1.1164 - val_auc: 0.5987 - val_loss: 1.3409 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 256ms/step - auc: 0.6274 - loss: 1.1360 - val_auc: 0.6322 - val_loss: 1.2286 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 286ms/step - auc: 0.7241 - loss: 1.0832 - val_auc: 0.6683 - val_loss: 1.1621 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 265ms/step - auc: 0.7663 - loss: 1.0454 - val_auc: 0.6665 - val_loss: 1.1778 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 233ms/step - auc: 0.7981 - loss: 0.9937 - val_auc: 0.6814 - val_loss: 1.1751 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 237ms/step - auc: 0.8177 - loss: 0.9833 - val_auc: 0.6969 - val_loss: 1.1689 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275ms/step - auc: 0.8061 - loss: 0.9730 - val_auc: 0.6834 - val_loss: 1.1533 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 310ms/step - auc: 0.8198 - loss: 0.9920 - val_auc: 0.6910 - val_loss: 1.1394 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 265ms/step - auc: 0.8633 - loss: 0.9618 - val_auc: 0.6917 - val_loss: 1.1311 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 271ms/step - auc: 0.8893 - loss: 0.9489 - val_auc: 0.7109 - val_loss: 1.1325 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 341ms/step - auc: 0.8451 - loss: 1.0185 - val_auc: 0.7072 - val_loss: 1.1318 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 270ms/step - auc: 0.8832 - loss: 0.9547 - val_auc: 0.6968 - val_loss: 1.1332 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 303ms/step - auc: 0.8820 - loss: 0.9520 - val_auc: 0.6994 - val_loss: 1.1336 - learning_rate: 1.0000e-05\n",
      "Epoch 16/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 276ms/step - auc: 0.8433 - loss: 0.9415 - val_auc: 0.7020 - val_loss: 1.1340 - learning_rate: 1.0000e-05\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 213ms/step\n",
      "{0: ([0.608294930875576, 0.6165311653116532, 0.4883720930232558, 0.6073980664144598], 0.24180327868852458, 0.59)}\n",
      "Epoch 1/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 608ms/step - auc: 0.4801 - loss: 1.4040 - val_auc: 0.5770 - val_loss: 1.2438 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 270ms/step - auc: 0.5816 - loss: 1.1209 - val_auc: 0.5351 - val_loss: 1.1346 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 261ms/step - auc: 0.6498 - loss: 1.0890 - val_auc: 0.6685 - val_loss: 1.2305 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275ms/step - auc: 0.7531 - loss: 1.1912 - val_auc: 0.6436 - val_loss: 1.2110 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 247ms/step - auc: 0.7350 - loss: 1.0660 - val_auc: 0.6840 - val_loss: 1.1441 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 265ms/step - auc: 0.8294 - loss: 1.0219 - val_auc: 0.6795 - val_loss: 1.1451 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 271ms/step - auc: 0.8584 - loss: 1.0256 - val_auc: 0.6976 - val_loss: 1.1548 - learning_rate: 1.0000e-04\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x446caedd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 186ms/step\n",
      "{0: ([0.608294930875576, 0.6165311653116532, 0.4883720930232558, 0.6073980664144598], 0.24180327868852458, 0.59), 1: ([0.5637480798771122, 0.5487804878048781, 0.4277408637873754, 0.6128625472887768], 0.25, 0.61)}\n",
      "Epoch 1/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 388ms/step - auc: 0.4755 - loss: 1.4343 - val_auc: 0.4562 - val_loss: 1.2193 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 253ms/step - auc: 0.5426 - loss: 1.1434 - val_auc: 0.5544 - val_loss: 1.2464 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 279ms/step - auc: 0.6361 - loss: 1.1417 - val_auc: 0.5246 - val_loss: 1.2056 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 319ms/step - auc: 0.7347 - loss: 1.1662 - val_auc: 0.5697 - val_loss: 1.1795 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 255ms/step - auc: 0.8134 - loss: 1.0783 - val_auc: 0.5870 - val_loss: 1.2116 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 245ms/step - auc: 0.6731 - loss: 0.9950 - val_auc: 0.5355 - val_loss: 1.2446 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 267ms/step - auc: 0.7535 - loss: 1.1419 - val_auc: 0.5628 - val_loss: 1.2194 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 297ms/step - auc: 0.9004 - loss: 0.9533 - val_auc: 0.5672 - val_loss: 1.2091 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 250ms/step - auc: 0.8733 - loss: 1.0161 - val_auc: 0.5538 - val_loss: 1.1837 - learning_rate: 1.0000e-04\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x444f85990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 192ms/step\n",
      "{0: ([0.608294930875576, 0.6165311653116532, 0.4883720930232558, 0.6073980664144598], 0.24180327868852458, 0.59), 1: ([0.5637480798771122, 0.5487804878048781, 0.4277408637873754, 0.6128625472887768], 0.25, 0.61), 2: ([0.5852534562211982, 0.5203252032520325, 0.3945182724252492, 0.5985708280790247], 0.25, 0.61)}\n",
      "Epoch 1/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 420ms/step - auc: 0.4829 - loss: 1.3430 - val_auc: 0.4552 - val_loss: 1.3452 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 282ms/step - auc: 0.5051 - loss: 1.2115 - val_auc: 0.6271 - val_loss: 1.2302 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 268ms/step - auc: 0.5606 - loss: 1.1352 - val_auc: 0.6639 - val_loss: 1.1641 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 246ms/step - auc: 0.7493 - loss: 1.0411 - val_auc: 0.6742 - val_loss: 1.1904 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 260ms/step - auc: 0.7375 - loss: 1.0540 - val_auc: 0.6435 - val_loss: 1.1419 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 267ms/step - auc: 0.6968 - loss: 1.1213 - val_auc: 0.6694 - val_loss: 1.1344 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 292ms/step - auc: 0.8257 - loss: 1.0450 - val_auc: 0.6628 - val_loss: 1.1342 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 310ms/step - auc: 0.8043 - loss: 1.0496 - val_auc: 0.6820 - val_loss: 1.1188 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 289ms/step - auc: 0.7852 - loss: 0.9404 - val_auc: 0.6845 - val_loss: 1.1072 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 278ms/step - auc: 0.8604 - loss: 1.0104 - val_auc: 0.6621 - val_loss: 1.1262 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 280ms/step - auc: 0.8371 - loss: 0.9492 - val_auc: 0.6773 - val_loss: 1.0801 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 279ms/step - auc: 0.8561 - loss: 0.9322 - val_auc: 0.6686 - val_loss: 1.0918 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 308ms/step - auc: 0.8992 - loss: 0.8421 - val_auc: 0.7105 - val_loss: 1.0789 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 291ms/step - auc: 0.8626 - loss: 0.8437 - val_auc: 0.7099 - val_loss: 1.0754 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 281ms/step - auc: 0.8542 - loss: 0.8257 - val_auc: 0.6946 - val_loss: 1.0674 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 280ms/step - auc: 0.9060 - loss: 0.7842 - val_auc: 0.6748 - val_loss: 1.3130 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 273ms/step - auc: 0.8768 - loss: 0.9187 - val_auc: 0.7563 - val_loss: 1.0980 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 282ms/step - auc: 0.8517 - loss: 0.8127 - val_auc: 0.6830 - val_loss: 1.3196 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 281ms/step - auc: 0.9350 - loss: 0.9052 - val_auc: 0.6879 - val_loss: 1.2122 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275ms/step - auc: 0.8735 - loss: 0.7120 - val_auc: 0.6905 - val_loss: 1.0839 - learning_rate: 1.0000e-04\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 164ms/step\n",
      "{0: ([0.608294930875576, 0.6165311653116532, 0.4883720930232558, 0.6073980664144598], 0.24180327868852458, 0.59), 1: ([0.5637480798771122, 0.5487804878048781, 0.4277408637873754, 0.6128625472887768], 0.25, 0.61), 2: ([0.5852534562211982, 0.5203252032520325, 0.3945182724252492, 0.5985708280790247], 0.25, 0.61), 3: ([0.5745007680491552, 0.6626016260162602, 0.43272425249169433, 0.612442202606137], 0.2599531615925058, 0.5)}\n",
      "Epoch 1/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 392ms/step - auc: 0.4349 - loss: 1.4014 - val_auc: 0.5380 - val_loss: 1.4371 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 280ms/step - auc: 0.6084 - loss: 1.1197 - val_auc: 0.5165 - val_loss: 1.2666 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 252ms/step - auc: 0.7283 - loss: 1.1420 - val_auc: 0.5302 - val_loss: 1.2293 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 263ms/step - auc: 0.7240 - loss: 1.0799 - val_auc: 0.5180 - val_loss: 1.3138 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 267ms/step - auc: 0.7308 - loss: 1.1233 - val_auc: 0.5250 - val_loss: 1.2421 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 275ms/step - auc: 0.7976 - loss: 1.0324 - val_auc: 0.5522 - val_loss: 1.2302 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 286ms/step - auc: 0.8099 - loss: 0.9962 - val_auc: 0.5459 - val_loss: 1.2325 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 252ms/step - auc: 0.8541 - loss: 1.0027 - val_auc: 0.5394 - val_loss: 1.2296 - learning_rate: 1.0000e-04\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 192ms/step\n",
      "{0: ([0.608294930875576, 0.6165311653116532, 0.4883720930232558, 0.6073980664144598], 0.24180327868852458, 0.59), 1: ([0.5637480798771122, 0.5487804878048781, 0.4277408637873754, 0.6128625472887768], 0.25, 0.61), 2: ([0.5852534562211982, 0.5203252032520325, 0.3945182724252492, 0.5985708280790247], 0.25, 0.61), 3: ([0.5745007680491552, 0.6626016260162602, 0.43272425249169433, 0.612442202606137], 0.2599531615925058, 0.5), 4: ([0.6835637480798772, 0.6321138211382115, 0.43023255813953487, 0.5670449768810424], 0.25, 0.61)}\n"
     ]
    }
   ],
   "source": [
    "with open(f\"augmentation_data/images_test.pkl\", \"rb\") as file:\n",
    "    images_test = pickle.load(file)\n",
    "with open(f\"augmentation_data/labels_test.pkl\", \"rb\") as file:\n",
    "    labels_test = pickle.load(file)\n",
    "\n",
    "\n",
    "for aug_idx in range(0, 5):\n",
    "    \n",
    "    images\n",
    "    \n",
    "    if aug_idx == 0:\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    for run, (train_idx, val_idx) in enumerate(skf.split(images_clean, np.argmax(labels_clean, axis=1))):\n",
    "    \n",
    "        tf.keras.backend.clear_session()\n",
    "                \n",
    "        images_train, images_val = images_clean[train_idx], images_clean[val_idx]\n",
    "        labels_train, labels_val = labels_clean[train_idx], labels_clean[val_idx]\n",
    "           \n",
    "        train_dataset = create_train_dataset(images_train, labels_train)\n",
    "        val_dataset = create_val_dataset(images_val, labels_val)\n",
    "        \n",
    "        steps_per_epoch = len(images_train) // BATCH_SIZE\n",
    "        validation_steps = len(images_val) // BATCH_SIZE\n",
    "        \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        reduceLR_callback = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.1,\n",
    "            patience=3,\n",
    "            min_lr=1e-6\n",
    "        )     \n",
    "        \n",
    "        model = create_mobilenetv2_model(IMAGE_SIZE)\n",
    "                    \n",
    "        model.fit(\n",
    "            train_dataset,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=50,\n",
    "            validation_data=val_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            verbose=1,\n",
    "            callbacks=[early_stopping, reduceLR_callback]) #######BIRNE\n",
    "        \n",
    "        sub_eval = evaluate_model(model, images_test, labels_test)\n",
    "        \n",
    "        evaluations[run] = sub_eval\n",
    "        print(evaluations)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-26T11:06:39.416037Z",
     "start_time": "2025-03-26T11:04:47.962940Z"
    }
   },
   "id": "a3c90a9d61ce647e",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6d8144ac058d7fdc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
