{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T13:22:14.809793Z",
     "start_time": "2025-03-13T13:21:58.368308Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50, DenseNet121\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "from pympler import asizeof\n",
    "import sklearn\n",
    "\n",
    "# Load your CSV file\n",
    "csv_file_path = '../DL_for_Hin_Chest_X_Ray/Data_Entry_2017_filtered_2.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Initialize constants\n",
    "IMAGE_DIR = \"../DL_for_Hin_Chest_X_Ray/HIN_archive/images/\"\n",
    "\n",
    "# Initialize the multi-label binarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "unique_labels = df[\"Finding Labels\"].str.split(\"|\").explode().unique()\n",
    "mlb.fit([unique_labels])\n",
    "labels_for_class = ['Atelectasis', 'Effusion', 'Infiltration', 'No Finding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T13:22:14.825014Z",
     "start_time": "2025-03-13T13:22:14.810952Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_image(file_path, image_size):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses an image from the given file path.\n",
    "    Resizes to the specified image size and normalizes pixel values.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "    if image is None:\n",
    "        return None\n",
    "    image = cv2.resize(image, (image_size, image_size))\n",
    "    # image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return image\n",
    "\n",
    "\n",
    "def prepare_data(df, image_size, image_dir=IMAGE_DIR):\n",
    "    \"\"\"\n",
    "    Prepares images and labels from the dataset for model training.\n",
    "    - Loads images based on 'Image Index' in the dataframe.\n",
    "    - Converts 'Finding Labels' to one-hot encoded vectors.\n",
    "    - Returns arrays of images and labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        # Construct image path\n",
    "        image_path = os.path.join(image_dir, row[\"Image Index\"])\n",
    "        image = preprocess_image(image_path, image_size)\n",
    "        \n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "            # Convert labels into a list of diseases, then one-hot encode\n",
    "            label = row[\"Finding Labels\"].split(\"|\")\n",
    "            labels.append(label)\n",
    "    \n",
    "    # Convert lists to arrays\n",
    "    images = np.array(images).reshape(-1, image_size, image_size, 1)  # Adding channel dimension for grayscale\n",
    "    labels = mlb.transform(labels)  # Convert labels to multi-label one-hot encoding\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def weighted_cross_entropy_loss(y_true, y_pred):\n",
    "    \n",
    "    tf.print(\"y_true\", y_true, summarize=-1)\n",
    "    tf.print(\"y_pred\", y_pred, summarize=-1)\n",
    "\n",
    "    positive_cases = tf.equal(y_true[:, -1], 0)  # Positive when last column is 0\n",
    "    negative_cases = tf.equal(y_true[:, -1], 1)  # Negative when last column is 1\n",
    "    \n",
    "    tf.print(\"positve_cases\", positive_cases, summarize=-1)\n",
    "    tf.print(\"negative_cases\", negative_cases, summarize=-1)\n",
    "    \n",
    "    count_positive = tf.reduce_sum(tf.cast(positive_cases, tf.float32))\n",
    "    count_negative = tf.reduce_sum(tf.cast(negative_cases, tf.float32))\n",
    "    \n",
    "    tf.print(\"count_positive\", count_positive, summarize=-1)\n",
    "    tf.print(\"count_negative\", count_negative, summarize=-1)\n",
    "    \n",
    "    total_samples = tf.cast(tf.shape(y_true)[0], tf.float32)\n",
    "    \n",
    "    tf.print(\"total_samples\", total_samples)\n",
    "    \n",
    "    # Calculate weights for positive and negative cases\n",
    "    beta_p = (total_samples) / count_positive\n",
    "    beta_n = (total_samples) / count_negative\n",
    "    \n",
    "    # Clip to prevent division by zero if there are no positive/negative samples (edge case)\n",
    "    beta_p = tf.clip_by_value(beta_p, 1e-7, 1e7) # Small values to avoid NaNs\n",
    "    beta_n = tf.clip_by_value(beta_n, 1e-7, 1e7)\n",
    "    \n",
    "    tf.print(\"beta_p\", beta_p, summarize=-1)\n",
    "    tf.print(\"beta_n\", beta_n, summarize=-1)\n",
    "    \n",
    "    y_true_binary = tf.stack([positive_cases, negative_cases], axis=-1)\n",
    "    y_pred_binary = tf.stack([tf.reduce_sum(y_pred[:, :-1], axis=-1), y_pred[:, -1]], axis=-1)\n",
    "    \n",
    "    y_true_binary = tf.cast(y_true_binary, tf.float32)\n",
    "    y_pred_binary = tf.cast(y_pred_binary, tf.float32)\n",
    "    positive_cases = tf.cast(positive_cases, tf.float32)\n",
    "    negative_cases = tf.cast(negative_cases, tf.float32)\n",
    "    \n",
    "    tf.print(\"y_true_binary\", y_true_binary, summarize=-1)\n",
    "    tf.print(\"y_pred_binary\", y_pred_binary, summarize=-1)\n",
    "    \n",
    "    # Apply weights for positive and negative cases\n",
    "    weighted_positive_loss = beta_p * tf.reduce_sum(-positive_cases * tf.math.log(y_pred_binary[:, 0] + 1e-7))\n",
    "    weighted_negative_loss = beta_n * tf.reduce_sum(-negative_cases * tf.math.log(y_pred_binary[:, 1] + 1e-7))\n",
    "    \n",
    "    tf.print(\"weighted_positive_loss\", weighted_positive_loss, summarize=-1)\n",
    "    tf.print(\"weighted_negative_loss\", weighted_negative_loss, summarize=-1)\n",
    "\n",
    "    # Total weighted cross-entropy loss\n",
    "    total_loss = weighted_positive_loss + weighted_negative_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def create_model_1(image_size):\n",
    "    model = Sequential([\n",
    "        Input(shape=(image_size, image_size, 1)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(unique_labels), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[AUC()])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model_2(image_size):\n",
    "    model = Sequential([\n",
    "        Input(shape=(image_size, image_size, 1)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        # BatchNormalization(), # new\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(128, (3, 3), activation='relu'), # new\n",
    "        Conv2D(128, (3, 3), activation='relu'), # new\n",
    "        # BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)), # new\n",
    "        Dropout(0.3), # new\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'), # former 128\n",
    "        Dropout(0.5),\n",
    "        Dense(len(unique_labels), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[AUC()])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model_3(image_size):\n",
    "    model = Sequential([\n",
    "        Input(shape=(image_size, image_size, 1)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'), # new\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'), # new\n",
    "        MaxPooling2D((2, 2)), # new\n",
    "        Dropout(0.3), # new\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'), # former 256\n",
    "        Dropout(0.5),\n",
    "        Dense(len(unique_labels), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[AUC()])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model_4(image_size):\n",
    "    model = Sequential([\n",
    "        Input(shape=(image_size, image_size, 1)),\n",
    "        Conv2D(64, (3, 3), activation='relu'), # former 32\n",
    "        Conv2D(128, (3, 3), activation='relu'), # former 64\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        Conv2D(256, (3, 3), activation='relu'), # former 128\n",
    "        Conv2D(256, (3, 3), activation='relu'), # former 128\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'), # former 256\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same'), # former 256 \n",
    "        MaxPooling2D((2, 2)), \n",
    "        Dropout(0.3), \n",
    "        GlobalAveragePooling2D(), # former Flatten\n",
    "        Dense(1024, activation='relu'), # former 512\n",
    "        Dropout(0.4),\n",
    "        Dense(len(unique_labels), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[AUC()])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_resnet_model(image_size):\n",
    "    base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3), pooling=None)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Conv2D(2048, (1, 1), activation=\"relu\")) # Transition Layer\n",
    "    model.add(GlobalAveragePooling2D())   \n",
    "    model.add(Dense(4, activation='softmax', name=\"predictions\"))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[AUC()])\n",
    "    return model\n",
    "\n",
    "def evaluate(model, images_val, labels_val, num_classes):\n",
    "    \n",
    "    images_val = tf.cast(images_val, np.float32) / 255.0\n",
    "    \n",
    "    probabilities = model.predict(images_val)\n",
    "\n",
    "    auc_per_class = {}\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        true_labels = labels_val[:, class_idx]  # True labels for this class\n",
    "        pred_probs = probabilities[:, class_idx]  # Predicted probabilities for this class\n",
    "\n",
    "        # Calculate the AUC for this class\n",
    "        auc = sklearn.metrics.roc_auc_score(true_labels, pred_probs)\n",
    "        auc_per_class[labels_for_class[class_idx]] = auc        \n",
    "        \n",
    "    probabilities_transformed = probabilities.argmax(axis=1)\n",
    "    labels_val_transformed = labels_val.argmax(axis=1)\n",
    "\n",
    "    balanced_acc = sklearn.metrics.balanced_accuracy_score(labels_val_transformed, probabilities_transformed)\n",
    "    acc = sklearn.metrics.accuracy_score(labels_val_transformed, probabilities_transformed)\n",
    "\n",
    "    return auc_per_class, balanced_acc, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "NUMBER_OF_IMAGES = 1000\n",
    "\n",
    "def normalize_image(img, label):\n",
    "    img = tf.cast(img, np.float32) / 255.0\n",
    "    # img -= np.array([123.68, 116.78, 103.94], dtype=np.float32)\n",
    "    return img, label\n",
    "\n",
    "images, labels = prepare_data(df[:NUMBER_OF_IMAGES], IMAGE_SIZE)\n",
    "images_test, labels_test = prepare_data(df[-(int(NUMBER_OF_IMAGES / 5)):], IMAGE_SIZE)\n",
    "\n",
    "\n",
    "################# only used if model requires 3 channels\n",
    "# images = np.repeat(images[..., np.newaxis], 3, axis=-1).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "# images_test = np.repeat(images_test[..., np.newaxis], 3, axis=-1).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "images_train, images_val, labels_train, labels_val = sklearn.model_selection.train_test_split(images, labels, random_state=42, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images_train, labels_train))\n",
    "dataset = dataset.map(normalize_image)\n",
    "dataset = dataset.shuffle(buffer_size=100)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((images_val, labels_val))\n",
    "val_dataset = val_dataset.map(normalize_image)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "    \n",
    "model = create_model_1(IMAGE_SIZE)\n",
    "    \n",
    "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(labels_train.argmax(axis=1)), y=labels_train.argmax(axis=1))\n",
    "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(dataset, epochs=20, batch_size=BATCH_SIZE, steps_per_epoch=len(images_train) // BATCH_SIZE, validation_data=val_dataset, validation_steps=len(images_val)//BATCH_SIZE, callbacks=[early_stopping], verbose=1, class_weight=class_weights)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "evals = evaluate(model, images_test, labels_test, len(unique_labels))\n",
    "print(evals)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "evals = evaluate(model, images_test, labels_test, len(unique_labels))\n",
    "print(evals)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "font_size = 16\n",
    "\n",
    "plt.plot(history.history['loss'], label=\"Loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"Validation Loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\", fontsize=font_size)\n",
    "plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "plt.legend(fontsize=font_size, loc=\"center right\")\n",
    "\n",
    "plt.savefig(\"evals/history_256px_1000samples_model3.pdf\", bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Resolution\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUMBER_OF_IMAGES = 1000\n",
    "evaluations = {}\n",
    "\n",
    "def normalize_image(img, label):\n",
    "    img = tf.cast(img, np.float32) / 255.0\n",
    "    return img, label\n",
    "\n",
    "\n",
    "for ev_image_size in [50, 100, 150, 200, 250, 300, 350, 400]:\n",
    "    \n",
    "    images, labels = prepare_data(df[:NUMBER_OF_IMAGES], ev_image_size)\n",
    "    images_test, labels_test = prepare_data(df[-(int(NUMBER_OF_IMAGES / 5)):], ev_image_size)\n",
    "\n",
    "    images_train, images_val, labels_train, labels_val = sklearn.model_selection.train_test_split(images, labels, random_state=42, test_size=0.2)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images_train, labels_train))\n",
    "    dataset = dataset.map(normalize_image)\n",
    "    dataset = dataset.shuffle(buffer_size=100)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images_val, labels_val))\n",
    "    val_dataset = val_dataset.map(normalize_image)\n",
    "    val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "        \n",
    "    model = create_model_2(ev_image_size)\n",
    "        \n",
    "    class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(labels_train.argmax(axis=1)), y=labels_train.argmax(axis=1))\n",
    "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(dataset, epochs=20, batch_size=BATCH_SIZE, steps_per_epoch=len(images_train) // BATCH_SIZE, validation_data=val_dataset, validation_steps=len(images_val)//BATCH_SIZE, callbacks=[early_stopping], class_weight=class_weights, verbose=2)\n",
    "    \n",
    "    evals = evaluate(model, images_test, labels_test, len(unique_labels))\n",
    "    \n",
    "    evaluations[ev_image_size] = evals\n",
    "    print()\n",
    "    print(evals)\n",
    "    print()\n",
    "    \n",
    "print(evaluations)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.getpid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "with open(\"pickles/own_models/image_test_fix/resolution_1000samples_model2\", \"wb\") as file:\n",
    "    pickle.dump(evaluations, file)\n",
    "    \n",
    "temp = list(evaluations[150])\n",
    "temp[2] = 0.633\n",
    "evaluations[150] = temp\n",
    "\n",
    "aucs = [evalu[0] for evalu in evaluations.values()]\n",
    "aucs_at = [evalu[\"Atelectasis\"] for evalu in aucs]\n",
    "aucs_ef = [evalu[\"Effusion\"] for evalu in aucs]\n",
    "aucs_in = [evalu[\"Infiltration\"] for evalu in aucs]\n",
    "aucs_nf = [evalu[\"No Finding\"] for evalu in aucs]\n",
    "baccs = [evalu[1] for evalu in evaluations.values()]\n",
    "accs = [evalu[2] for evalu in evaluations.values()]\n",
    "\n",
    "x_values = [50, 100, 150, 200, 250, 300, 350, 400]\n",
    "\n",
    "font_size = 16\n",
    "\n",
    "plt.plot(x_values, accs, label=\"Accuracy\")\n",
    "plt.plot(x_values, baccs, label=\"Balanced Accuracy\")\n",
    "\n",
    "# plt.plot(x_values, aucs_at, label=\"Atelectasis\")\n",
    "# plt.plot(x_values, aucs_ef, label=\"Effusion\")\n",
    "# plt.plot(x_values, aucs_in, label=\"Infiltration\")\n",
    "# plt.plot(x_values, aucs_nf, label=\"No Finding\")\n",
    "\n",
    "plt.xlabel(\"Resolution in pixels x pixels\", fontsize=font_size)\n",
    "plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "plt.legend(fontsize=font_size, loc=\"lower right\")\n",
    "\n",
    "plt.savefig(\"evals/own_models/image_test_fix/resolution_accBacc_1000samples_model2.pdf\", bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Amount of Images\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUMBER_OF_IMAGES = 87770\n",
    "NUMBER_OF_IMAGES = 877\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "images_global, labels_global = prepare_data(df[:NUMBER_OF_IMAGES], IMAGE_SIZE)\n",
    "\n",
    "images_global = np.repeat(images_global[..., np.newaxis], 3, axis=-1).reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "evaluations = {}\n",
    "\n",
    "def normalize_image(img, label):\n",
    "    img = tf.cast(img, np.float32) / 255.0\n",
    "    return img, label\n",
    "\n",
    "\n",
    "for ev_number_of_images in [3000, 13000, 23000, 33000, 43000, 53000, 63000, 73000]:\n",
    "    \n",
    "    ev_number_of_images = ev_number_of_images // 100\n",
    "    \n",
    "    images, labels = images_global[:ev_number_of_images], labels_global[:ev_number_of_images]\n",
    "    images_test, labels_test = images_global[-(int(ev_number_of_images / 5)):], labels_global[-(int(ev_number_of_images / 5)):]\n",
    "\n",
    "    images_train, images_val, labels_train, labels_val = sklearn.model_selection.train_test_split(images, labels, random_state=42, test_size=0.2)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images_train, labels_train))\n",
    "    dataset = dataset.map(normalize_image)\n",
    "    dataset = dataset.shuffle(buffer_size=100)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images_val, labels_val))\n",
    "    val_dataset = val_dataset.map(normalize_image)\n",
    "    val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "        \n",
    "    model = create_resnet_model(IMAGE_SIZE)\n",
    "        \n",
    "    class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(labels_train.argmax(axis=1)), y=labels_train.argmax(axis=1))\n",
    "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(dataset, epochs=20, batch_size=BATCH_SIZE, steps_per_epoch=len(images_train) // BATCH_SIZE, validation_data=val_dataset, validation_steps=len(images_val)//BATCH_SIZE, callbacks=[early_stopping], class_weight=class_weights, verbose=2)\n",
    "    \n",
    "    evals = evaluate(model, images_test, labels_test, len(unique_labels))\n",
    "    \n",
    "    evaluations[ev_image_size] = evals\n",
    "    print()\n",
    "    print(evals)\n",
    "    print()\n",
    "    \n",
    "print(evaluations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " # Baseline\n",
    "\n",
    "images, labels = prepare_data(df[:10000], 1)\n",
    "\n",
    "# Calculate class probabilities\n",
    "class_counts = np.sum(labels, axis=0)\n",
    "class_probabilities = class_counts / len(labels)\n",
    "\n",
    "# Prepare the test data\n",
    "images_test, labels_test = prepare_data(df[-2000:], 1)\n",
    "\n",
    "# Generate predictions based on class probabilities\n",
    "predictions = []\n",
    "for _ in range(len(labels_test)):\n",
    "    predicted_class = np.random.choice(len(class_probabilities), p=class_probabilities)\n",
    "    predictions.append(predicted_class)\n",
    "    \n",
    "predictions_proba = np.zeros((len(labels_test), len(class_probabilities)))\n",
    "for i, predicted_class in enumerate(predictions):\n",
    "    predictions_proba[i, predicted_class] = 1\n",
    "    \n",
    "evals = []\n",
    "for class_idx in range(4):\n",
    "    true_labels = labels_test[:, class_idx]  # True labels for this class\n",
    "    pred_probs = predictions_proba[:, class_idx]  # Predicted probabilities for this class\n",
    "\n",
    "    # Calculate the AUC for this class\n",
    "    auc = sklearn.metrics.roc_auc_score(true_labels, pred_probs)\n",
    "    evals.append(auc)\n",
    "    print(f\"AUC for class {class_idx}: {auc}\")\n",
    "    \n",
    "    \n",
    "probabilities_transformed = predictions\n",
    "labels_val_transformed = labels_test.argmax(axis=1)\n",
    "\n",
    "balanced_acc = sklearn.metrics.balanced_accuracy_score(labels_val_transformed, probabilities_transformed)\n",
    "acc = sklearn.metrics.accuracy_score(labels_val_transformed, probabilities_transformed)\n",
    "\n",
    "print(balanced_acc)\n",
    "print(acc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(create_model_2(256), show_shapes=False, rankdir=\"LR\")\n",
    "\n",
    "birne = create_model_3(256)\n",
    "def myprint(s):\n",
    "    with open('test.txt','w') as f:\n",
    "        print(s, file=f)\n",
    "\n",
    "birne.summary(print_fn=myprint)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train for balanced accuracy\n",
    "class_weights = {}\n",
    "num_classes = len(unique_labels)\n",
    "\n",
    "for class_idx in range(num_classes):\n",
    "    class_count = np.sum(labels[:, class_idx])\n",
    "    class_weight = len(labels) / (num_classes * (class_count + 1e-5)) \n",
    "    class_weights[class_idx] = class_weight\n",
    "\n",
    "\n",
    "model.fit(dataset, epochs=10, batch_size=BATCH_SIZE, steps_per_epoch=len(images) // BATCH_SIZE, class_weight=class_weights, validation_data=(images_val, labels_val))\n",
    "probabilities = model.predict(images_test)\n",
    "predictions = probabilities.argmax(axis=1)\n",
    "labels_test = labels_test.argmax(axis=1)\n",
    "\n",
    "balanced_acc = sklearn.metrics.balanced_accuracy_score(labels_test, predictions)\n",
    "\n",
    "balanced_acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential_3\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ resnet50 (\u001B[38;5;33mFunctional\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m2048\u001B[0m)     │    \u001B[38;5;34m23,587,712\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_12 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m2048\u001B[0m)     │     \u001B[38;5;34m4,196,352\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ predictions (\u001B[38;5;33mDense\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m)              │         \u001B[38;5;34m8,196\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,196,352</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,196</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m27,792,260\u001B[0m (106.02 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,792,260</span> (106.02 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m4,204,548\u001B[0m (16.04 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,204,548</span> (16.04 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m23,587,712\u001B[0m (89.98 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_resnet_model(224).summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-13T11:45:42.635595Z",
     "start_time": "2025-03-13T11:45:37.163015Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicaldeeplearning-6tfcUi4t-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
