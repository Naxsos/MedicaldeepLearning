{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T16:38:38.888246Z",
     "start_time": "2025-02-13T16:38:38.883337Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cardiomegaly', 'Emphysema', 'Effusion', 'No Finding', 'Hernia',\n",
       "       'Infiltration', 'Mass', 'Nodule', 'Atelectasis', 'Pneumothorax',\n",
       "       'Pleural_Thickening', 'Pneumonia', 'Fibrosis', 'Edema',\n",
       "       'Consolidation'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your CSV file\n",
    "csv_file_path = '../DL_for_Hin_Chest_X_Ray/HIN_archive/Data_Entry_2017.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Initialize constants\n",
    "IMAGE_DIR = \"../DL_for_Hin_Chest_X_Ray/HIN_archive/images/\"\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# Initialize the multi-label binarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "unique_labels = df[\"Finding Labels\"].str.split(\"|\").explode().unique()\n",
    "mlb.fit([unique_labels])\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(file_path, image_size=IMAGE_SIZE):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses an image from the given file path.\n",
    "    Resizes to the specified image size and normalizes pixel values.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
    "    if image is None:\n",
    "        return None\n",
    "    image = cv2.resize(image, image_size)\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return image\n",
    "\n",
    "\n",
    "def prepare_data(df, image_dir=IMAGE_DIR, image_size=IMAGE_SIZE):\n",
    "    \"\"\"\n",
    "    Prepares images and labels from the dataset for model training.\n",
    "    - Loads images based on 'Image Index' in the dataframe.\n",
    "    - Converts 'Finding Labels' to one-hot encoded vectors.\n",
    "    - Returns arrays of images and labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Construct image path\n",
    "        image_path = os.path.join(image_dir, row[\"Image Index\"])\n",
    "        image = preprocess_image(image_path, image_size)\n",
    "        \n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "            # Convert labels into a list of diseases, then one-hot encode\n",
    "            label = row[\"Finding Labels\"].split(\"|\")\n",
    "            labels.append(label)\n",
    "    \n",
    "    # Convert lists to arrays\n",
    "    images = np.array(images).reshape(-1, image_size[0], image_size[1], 1)  # Adding channel dimension for grayscale\n",
    "    labels = mlb.transform(labels)  # Convert labels to multi-label one-hot encoding\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I569354/Library/Caches/pypoetry/virtualenvs/medicaldeeplearning-6tfcUi4t-py3.10/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-02-13 20:55:05.225148: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-02-13 20:55:05.225270: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-02-13 20:55:05.225303: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739476505.226052 28171155 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1739476505.226237 28171155 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(unique_labels), activation='sigmoid')  # For multi-label classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m(df)\n\u001b[1;32m      3\u001b[0m image_sizes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m), (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m), (\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)]\n\u001b[1;32m      4\u001b[0m percentages \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_data' is not defined"
     ]
    }
   ],
   "source": [
    "images, labels = prepare_data(df)\n",
    "\n",
    "image_sizes = [(64, 64), (128, 128), (256, 256)]\n",
    "percentages = [0.1, 0.2, 0.3]\n",
    "results = {}\n",
    "\n",
    "for image_size in image_sizes:\n",
    "    for pct in percentages:\n",
    "        # Resize images\n",
    "        resized_images = np.array(images).reshape(-1, image_size[0], image_size[1], 1)\n",
    "        # Slice data based on percentage\n",
    "        subset_images = resized_images[:int(pct * len(images))]\n",
    "        subset_labels = labels[:int(pct * len(labels))]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(subset_images, subset_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "        # Evaluate and store accuracy\n",
    "        accuracy = model.evaluate(subset_images, subset_labels)\n",
    "        results[(image_size, pct)] = accuracy\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicaldeeplearning-6tfcUi4t-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
